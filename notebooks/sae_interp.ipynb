{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d6b3b0-a4c8-46ca-b785-bf521ce91b8d",
   "metadata": {},
   "source": [
    "### Load in the SAEs from Huggingface Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c06caf-8e84-46f1-9a55-d9a16f0bae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_dependencies():\n",
    "    ! git clone https://github.com/amirabdullah19852020/sae.git\n",
    "    ! cd sae && pip install .\n",
    "    ! git clone https://github.com/withmartian/TinySQL.git\n",
    "    ! cd TinySQL && pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ead171-4c94-4fd6-8d84-90e1e47649a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import psutil\n",
    "import re\n",
    "\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "\n",
    "import nnsight\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import sae\n",
    "import torch\n",
    "import torch.fx\n",
    "\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import snapshot_download\n",
    "import matplotlib.pyplot as plt\n",
    "from nnsight import NNsight, LanguageModel\n",
    "from plotly.subplots import make_subplots\n",
    "from sae import Sae\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from TinySQL import sql_interp_model_location\n",
    "from TinySQL.training_data.fragments import field_names, table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c1b085-52e8-446e-8b90-f9c59f2ff9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current process\n",
    "def process_info():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    \n",
    "    # Memory usage in MB\n",
    "    memory_info = process.memory_info()\n",
    "    print(f\"RSS: {memory_info.rss / (1024 ** 2):.2f} MB\")  # Resident Set Size\n",
    "    print(f\"VMS: {memory_info.vms / (1024 ** 2):.2f} MB\") \n",
    "\n",
    "process_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e5fa6-fcd2-4e48-9d15-f75ffebec6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_table_infos = table_names.get_TableInfo()\n",
    "all_field_infos = field_names.get_FieldInfo()\n",
    "\n",
    "all_table_names = []\n",
    "all_field_names = []\n",
    "\n",
    "for info in all_table_infos:\n",
    "    all_table_names.append(info.name)\n",
    "    all_table_names.extend(info.synonyms)\n",
    "\n",
    "for key, info in all_field_infos.items():\n",
    "    all_field_names.append(info.name)\n",
    "    all_field_names.extend(info.synonyms)\n",
    "\n",
    "all_table_names = [name.strip().lower() for name in all_table_names]\n",
    "\n",
    "all_field_names = [name.strip().lower() for name in all_field_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9215a96-a9b6-42cd-86f5-5e663ae3cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"withmartian/sql_interp_saes\"\n",
    "\n",
    "# Change this to work with another model alias.\n",
    "model_alias = \"saes_bm1_cs1\"\n",
    "cache_dir = \"working_directory\"\n",
    "seed = 42\n",
    "\n",
    "process_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91567a0a-9f42-4597-ac28-6cbfa56ee7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelDatasetFullName:\n",
    "    model_id: str\n",
    "    dataset_id: str\n",
    "    full_dataset_name: str\n",
    "    full_model_name: str\n",
    "\n",
    "    def load_model(self):\n",
    "        model = AutoModelForCausalLM.from_pretrained(full_model_name)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3878fa9-d799-4503-b84f-2d03fc689567",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SaeOutput:\n",
    "    sae_name: str\n",
    "    sae: Sae\n",
    "    text: str\n",
    "    tokens: list[str]\n",
    "    raw_acts: list[list[float]]\n",
    "    top_acts: list[list[float]]\n",
    "    top_indices: list[list[int]]\n",
    "\n",
    "    def restrict_to_positions(self, positions):\n",
    "        output = deepcopy(self)\n",
    "        output.raw_acts = [self.raw_acts[position] for position in positions]\n",
    "        output.top_acts = [self.top_acts[position] for position in positions]\n",
    "        output.top_indices = [self.top_indices[position] for position in positions]\n",
    "\n",
    "        # print(f\"Truncated indices, raw_acts and top_acts to {len(output.top_indices)}, {len(output.raw_acts)}, {len(output.top_acts)} from {len(self.top_indices)}, {len(self.raw_acts)}, {len(self.top_acts)}\")\n",
    "        return output\n",
    "        \n",
    "\n",
    "    def zero_out_except_top_n(self, scores, indices, n):\n",
    "        \"\"\"\n",
    "        Zero out all but the top n scores in the scores vector, preserving the order.\n",
    "        \"\"\"\n",
    "        if len(scores) != len(indices):\n",
    "            raise ValueError(\"Scores and indices lists must have the same length.\")\n",
    "    \n",
    "        if n <= 0:\n",
    "            return [0] * len(scores), indices\n",
    "    \n",
    "        # Pair scores with their original indices\n",
    "        paired = list(zip(scores, range(len(scores))))\n",
    "    \n",
    "        # Sort by score in descending order\n",
    "        paired.sort(key=lambda x: -x[0])\n",
    "    \n",
    "        # Get the indices of the top n scores\n",
    "        top_n_indices = [index for _, index in paired[:n]]\n",
    "    \n",
    "        # Create a new scores list with only the top n scores retained\n",
    "        filtered_scores = [scores[i] if i in top_n_indices else 0 for i in range(len(scores))]\n",
    "    \n",
    "        return filtered_scores, indices\n",
    "\n",
    "    def zero_out_except_top_n_for_multiple(self, scores_list, indices_list, n):\n",
    "        if len(scores_list) != len(indices_list):\n",
    "            raise ValueError(\"Scores and indices lists must have the same length.\")\n",
    "    \n",
    "        filtered_scores_list = []\n",
    "        filtered_indices_list = []\n",
    "    \n",
    "        for scores, indices in zip(scores_list, indices_list):\n",
    "            filtered_scores, filtered_indices = self.zero_out_except_top_n(scores, indices, n)\n",
    "            filtered_scores_list.append(filtered_scores)\n",
    "            filtered_indices_list.append(filtered_indices)\n",
    "    \n",
    "        return filtered_scores_list, filtered_indices_list\n",
    "\n",
    "    def reconstruction_error(self, k=128):\n",
    "        decoded_activations = self.decode_to_activations(k)\n",
    "        raw_acts = torch.tensor(self.raw_acts).cuda()\n",
    "\n",
    "        difference = decoded_activations - raw_acts\n",
    "\n",
    "        reconstruction_error = torch.norm(difference) / torch.norm(raw_acts)\n",
    "        return reconstruction_error.item()\n",
    "\n",
    "    def decode_to_activations(self, k=128):\n",
    "        filtered_acts, top_k_indices = self.zero_out_except_top_n_for_multiple(self.top_acts.copy(), self.top_indices.copy(), n=k)\n",
    "        return self.sae.decode(top_acts=torch.tensor(filtered_acts).cuda(), top_indices=torch.tensor(top_k_indices).cuda())\n",
    "    \n",
    "\n",
    "@dataclass \n",
    "class GroupedSaeOutput:\n",
    "    \"\"\"\n",
    "    Class that collects and analyzes SaeOutputs over several layers.\n",
    "    \"\"\"\n",
    "    sae_outputs_by_layer: dict[str, SaeOutput]\n",
    "    text: str\n",
    "    tokens: list[str]\n",
    "    tags_by_index: list[str]\n",
    "\n",
    "    def __init__(self, sae_outputs_by_layer, text, tokens):\n",
    "        self.sae_outputs_by_layer = sae_outputs_by_layer\n",
    "        self.layers = list(self.sae_outputs_by_layer.keys())\n",
    "        self.text = text\n",
    "        self.tokens = tokens\n",
    "        self.apply_tags()\n",
    "        self.context_position = None\n",
    "        self.response_position = None\n",
    "\n",
    "    def simplify_token(self, token):\n",
    "        return token.strip().lower().replace(\"Ä¡\", \"\")\n",
    "\n",
    "    def apply_tags(self):\n",
    "        self.tags_by_index = {}\n",
    "        self.tags_by_index = {i : [] for i in range(len(self.tokens))}\n",
    "        table_name = \"\"\n",
    "        for i, token in enumerate(self.tokens):\n",
    "            simple_token = self.simplify_token(token)\n",
    "            if simple_token == \"table\":\n",
    "                table_name = self.simplify_token(self.tokens[i+1])\n",
    "        for i, token in enumerate(self.tokens):\n",
    "            simple_token = self.simplify_token(token)\n",
    "            if table_name and (simple_token == table_name):\n",
    "                self.tags_by_index[i].append((\"TABLE\", simple_token))\n",
    "            elif simple_token in all_field_names and self.tokens[i-1] == \",\":\n",
    "                self.tags_by_index[i].append((\"FIELD\", simple_token))\n",
    "            else:\n",
    "                self.tags_by_index[i].append((\"NONE\", simple_token))\n",
    "\n",
    "            if simple_token == \"context\":\n",
    "                self.context_position = i\n",
    "            if simple_token == \"response\":\n",
    "                self.response_position = i\n",
    "        for i, token in enumerate(self.tokens):\n",
    "            tag_by_index = self.tags_by_index[i]\n",
    "            simple_token = self.simplify_token(token)\n",
    "            tags = [tag[0] for tag in tag_by_index]\n",
    "            if \"TABLE\" in tags:\n",
    "                if i < self.context_position:\n",
    "                    tag_by_index.append((\"INSTRUCTION_TABLE\", simple_token))\n",
    "                    print(f\"Found instruction table {simple_token}\")\n",
    "                else:\n",
    "                    tag_by_index.append((\"CONTEXT_TABLE\", simple_token))\n",
    "\n",
    "    def sae_outputs_for_positions(self, positions):\n",
    "        outputs_by_layer = {}\n",
    "        for layer, outputs in self.sae_outputs_by_layer.items():\n",
    "            sae_output = outputs\n",
    "            return_output = sae_output.restrict_to_positions(positions)\n",
    "            outputs_by_layer[layer] = return_output\n",
    "        return outputs_by_layer\n",
    "\n",
    "    def sae_activations_and_indices_for_tag_by_layer(self, tag):\n",
    "        positions = self.get_indices_by_tag(tag)\n",
    "        return self.sae_outputs_for_positions(positions)\n",
    "\n",
    "    def get_indices_by_tag(self, tag):\n",
    "        match_indices = []\n",
    "        for index, tag_tuples in self.tags_by_index.items():\n",
    "            tags = [tag_tuple[0] for tag_tuple in tag_tuples]\n",
    "            if tag in tags:\n",
    "                match_indices.append(index)\n",
    "        return match_indices\n",
    "\n",
    "    def get_reconstruction_error_by_layer(self, layer, k):\n",
    "        return sae_outputs_by_layer[layer].recontruction_error(k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5596f-ff6f-43fe-be3a-61f457715482",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = Path(\n",
    "    snapshot_download(repo_name, allow_patterns=f\"{model_alias}/*\", local_dir=cache_dir)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff27fe-0c74-46a2-acf2-d16a49e02794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(example):\n",
    "    alpaca_prompt = \"### Instruction: {} ### Context: {} ### Response: \"\n",
    "    example['prompt'] = alpaca_prompt.format(example['english_prompt'], example['create_statement'])\n",
    "    example['response'] = example['sql_statement']\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83cbdd3-5fee-459f-b5ab-e1ea381227aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadedSAES:\n",
    "    def __init__(self, dataset_name: str, full_model_name: str, model_alias: str,\n",
    "        tokenizer: AutoTokenizer, language_model: LanguageModel, layers: list[str],\n",
    "        layer_to_directory: dict, k: str, base_path: str, layer_to_saes: dict):\n",
    "\n",
    "        self.dataset_name = dataset_name\n",
    "        self.full_model_name = full_model_name\n",
    "        self.model_alias = model_alias\n",
    "        self.tokenizer = tokenizer\n",
    "        self.language_model = language_model\n",
    "        self.layers = layers\n",
    "        self.layer_to_directory = layer_to_directory\n",
    "        self.k = k\n",
    "        self.base_path = base_path\n",
    "        self.layer_to_saes = layer_to_saes\n",
    "\n",
    "        self.dataset = self.get_dataset()\n",
    "        self.mapped_dataset = self.dataset.map(format_example)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_all_subdirectories(path):\n",
    "        subdirectories = [\n",
    "            os.path.join(path, name) for name in os.listdir(path) \n",
    "            if os.path.isdir(os.path.join(path, name)) and not name.startswith(\".\")\n",
    "        ]\n",
    "        return subdirectories\n",
    "\n",
    "    def nnsight_eval_string_for_layer(self, layer: str):\n",
    "        \"\"\"\n",
    "        Converts transformer.h[0].mlp into self.language_model.transformer.h[0].mlp.output.save() for nnsight\n",
    "        \"\"\"\n",
    "        subbed_layer = re.sub(r'\\.([0-9]+)\\.', r'[\\1].', layer)\n",
    "        return f\"self.language_model.{subbed_layer}.output.save()\"\n",
    "\n",
    "    def encode_to_activations_for_layer(self, text: str, layer: str):\n",
    "        if \"bm1\" in self.full_model_name:\n",
    "            with self.language_model.trace() as tracer:\n",
    "                with tracer.invoke(text) as invoker:\n",
    "                    eval_string = self.nnsight_eval_string_for_layer(layer)\n",
    "                    my_output = eval(eval_string)\n",
    "        if len(my_output) > 1:\n",
    "            return my_output[0]\n",
    "        else:\n",
    "            return my_output\n",
    "\n",
    "    def encode_to_sae_for_layer(self, text: str, layer: str):\n",
    "        activations = self.encode_to_activations_for_layer(text, layer).cuda()\n",
    "        raw_acts = activations[0].cpu().detach().numpy().tolist()\n",
    "        relevant_sae = self.layer_to_saes[layer]\n",
    "        sae_acts_and_features = relevant_sae.encode(activations)\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "\n",
    "        top_acts = sae_acts_and_features.top_acts[0].cpu().detach().numpy().tolist()\n",
    "        top_indices = sae_acts_and_features.top_indices[0].cpu().detach().numpy().tolist()\n",
    "\n",
    "        sae_output = SaeOutput(\n",
    "            sae_name=layer, text=text, tokens=tokens, top_acts=top_acts, top_indices=top_indices, raw_acts=raw_acts, sae=relevant_sae\n",
    "        )\n",
    "        \n",
    "        return sae_output\n",
    "\n",
    "    def encode_to_all_saes(self, text: str):\n",
    "        sae_outputs_by_layer = {layer: self.encode_to_sae_for_layer(text=text, layer=layer) for layer in self.layers}\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        result = GroupedSaeOutput(sae_outputs_by_layer=sae_outputs_by_layer, text=text, tokens=tokens)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def load_from_path(model_alias: str, k: str):\n",
    "        k = str(k)\n",
    "        \n",
    "        base_path = f\"{cache_dir}/{model_alias}/k={k}\"\n",
    "        \n",
    "        print(f\"Loading from path {base_path}\")\n",
    "        subdirectories = LoadedSAES.get_all_subdirectories(base_path)\n",
    "        \n",
    "        layer_to_directory = {\n",
    "            directory.split(\"/\")[-1] : directory for directory in subdirectories\n",
    "        }\n",
    "\n",
    "        layer_to_directory = {layer: directory for layer, directory in layer_to_directory.items()}\n",
    "        layers = sorted(list(layer_to_directory.keys()))\n",
    "\n",
    "        with open(f\"{base_path}/model_config.json\",  \"r\") as f_in:\n",
    "            model_config = json.load(f_in)\n",
    "\n",
    "            dataset_name = model_config[\"dataset_name\"]\n",
    "            full_model_name = model_config[\"model_name\"]\n",
    "            language_model = LanguageModel(full_model_name)\n",
    "            tokenizer = language_model.tokenizer\n",
    "\n",
    "        layer_to_saes = {layer: Sae.load_from_disk(directory).cuda() for layer, directory in layer_to_directory.items()}\n",
    "\n",
    "        return LoadedSAES(dataset_name=dataset_name, full_model_name=full_model_name,\n",
    "                          model_alias=model_alias, layers=layers, layer_to_directory=layer_to_directory,\n",
    "                          tokenizer=tokenizer, k=k, base_path=base_path,\n",
    "                          layer_to_saes=layer_to_saes, language_model=language_model)\n",
    "\n",
    "    def get_dataset(self):\n",
    "        return load_dataset(self.dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f0a3dd-0975-419f-8480-bd978044d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_saes = LoadedSAES.load_from_path(model_alias=model_alias, k=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b903ab-c4fe-40c4-82d5-3a0705845e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaeCollector:\n",
    "    \"\"\"\n",
    "    This class is responsible for collecting a large amount of text,\n",
    "    assigning tags to each token for a feature name, and also SAE outputs.\n",
    "    These can then be used for probes and feature analysis.\n",
    "    (Still to add: ablations.)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loaded_saes, sample_size=10, restricted_tags=None):\n",
    "        self.loaded_saes = loaded_saes\n",
    "        self.restricted_tags = restricted_tags or []\n",
    "        self.sample_size = sample_size\n",
    "        self.mapped_dataset = loaded_saes.mapped_dataset\n",
    "        self.mapped_dataset.shuffle(seed=seed)\n",
    "        self.tokenizer = self.loaded_saes.tokenizer\n",
    "        self.layers = self.loaded_saes.layers\n",
    "        self.encoded_set = self.create_and_load_random_subset(sample_size=self.sample_size)\n",
    "\n",
    "    def get_texts(self):\n",
    "        return [element[\"prompt\"] for element in self.encoded_set]\n",
    "\n",
    "    def get_all_sae_outputs_for_tag(self, tag):\n",
    "        sae_outputs_for_tags = [element[\"encoding\"].sae_activations_and_indices_for_tag_by_layer(tag) for element in self.encoded_set]\n",
    "        return sae_outputs_for_tags\n",
    "\n",
    "    def get_prompt_and_encoding_for_text(self, feature):\n",
    "        prompt = feature[\"prompt\"]\n",
    "        response = feature[\"response\"]\n",
    "        encoding = self.loaded_saes.encode_to_all_saes(prompt)\n",
    "\n",
    "        return_dict = {\n",
    "            \"prompt\": prompt,\n",
    "            \"response\": response,\n",
    "            \"encoding\": encoding\n",
    "        }\n",
    "        return return_dict\n",
    "\n",
    "    def get_avg_reconstruction_error_for_all_k_and_layers(self):\n",
    "        all_reconstruction_errors = {layer: self.get_avg_reconstruction_error_for_all_k(layer) for layer in self.layers}\n",
    "        return all_reconstruction_errors\n",
    "\n",
    "    def get_avg_reconstruction_error_for_all_k(self, layer, min_range=0, max_range=256):\n",
    "        all_reconstruction_errors = {}\n",
    "        for element in tqdm(self.encoded_set):\n",
    "            encoding = element[\"encoding\"]\n",
    "\n",
    "            # Take k = min_range to min_range + 20, and then go at intervals of 10.\n",
    "            part1 = list(range(min_range, min_range+21))\n",
    "            part2 = list(range(min_range+20, max_range, 10))\n",
    "            result = sorted(list(set(part1 + part2)))\n",
    "\n",
    "            for k in result:\n",
    "                recon_error = encoding.sae_outputs_by_layer[layer].reconstruction_error(k)\n",
    "                curr_reconstruction_error_list = all_reconstruction_errors.get(k, [])\n",
    "                curr_reconstruction_error_list.append(recon_error)\n",
    "                all_reconstruction_errors[k] = curr_reconstruction_error_list\n",
    "\n",
    "        average_reconstruction_errors = {k: np.average(error_list) for k, error_list in all_reconstruction_errors.items()}\n",
    "        return average_reconstruction_errors\n",
    "\n",
    "    def create_and_load_random_subset(self, sample_size: int):\n",
    "        sampled_set = self.mapped_dataset['train'].select(range(sample_size))\n",
    "        encoded_set = []\n",
    "        for element in tqdm(sampled_set):\n",
    "            encoded_element = self.get_prompt_and_encoding_for_text(element)\n",
    "            encoded_set.append(encoded_element)\n",
    "        return encoded_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769553c-217f-4314-908b-e88b48404566",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_collector = SaeCollector(loaded_saes)\n",
    "sae_collector.get_texts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a74708-dbb6-4499-a593-e96beab82ca9",
   "metadata": {},
   "source": [
    "### Maximally activating latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715075f3-5a76-43aa-a5d6-ac1b987aed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_sort_weights(acts, indices):\n",
    "    \"\"\"\n",
    "    Compute the summed weights of each index and sort them in descending order.\n",
    "\n",
    "    Parameters:\n",
    "    acts (list of list of float): Nested list of scores.\n",
    "    indices (list of list of int): Nested list of indices corresponding to scores.\n",
    "\n",
    "    Returns:\n",
    "    list of tuple: Sorted elements by summed weights in descending order.\n",
    "    \"\"\"\n",
    "    # Dictionary to store summed weights for each index\n",
    "    weights = {}\n",
    "\n",
    "    for act_row, idx_row in zip(acts, indices):\n",
    "        for score, idx in zip(act_row, idx_row):\n",
    "            weights[idx] = weights.get(idx, 0) + score\n",
    "\n",
    "    # Sort by summed weight in descending order\n",
    "    sorted_weights = sorted(weights.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sorted_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874720fb-ae80-47f4-927d-db96cf76b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"INSTRUCTION_TABLE\"\n",
    "\n",
    "def get_sorted_weights_by_layer(tag):\n",
    "    results = sae_collector.get_all_sae_outputs_for_tag(tag)\n",
    "    aggregated_sae_features = {}\n",
    "    layers = sae_collector.layers\n",
    "    for layer in layers:\n",
    "        all_top_acts = []\n",
    "        all_top_indices = []\n",
    "        for element in results:\n",
    "            all_top_acts.extend(element[layer].top_acts)\n",
    "            all_top_indices.extend(element[layer].top_indices)\n",
    "    \n",
    "        sorted_weights = compute_and_sort_weights(all_top_acts, all_top_indices)\n",
    "        aggregated_sae_features[layer] = {\"top_acts\": all_top_acts, \"top_indices\": all_top_indices, \"sorted_weights\": sorted_weights}\n",
    "    return aggregated_sae_features\n",
    "\n",
    "\n",
    "def plot_layer_features(full_layer_data, tag, top_n=20, cols=2):\n",
    "    \"\"\"\n",
    "    Plot histograms for the top `n` features in each layer using a Plotly grid.\n",
    "\n",
    "    Parameters:\n",
    "    layer_data (dict): Dictionary where keys are layer names and values are lists of tuples \n",
    "                       (feature_num, weight), sorted in descending order by weight.\n",
    "    top_n (int): Number of top features to display for each layer.\n",
    "    cols (int): Number of columns in the grid layout.\n",
    "    \"\"\"\n",
    "    # Calculate rows based on number of layers and columns\n",
    "\n",
    "    layer_data = {layer: full_layer_data[layer][\"sorted_weights\"] for layer, layer_data in full_layer_data.items()}\n",
    "    \n",
    "    num_layers = len(layer_data)\n",
    "    rows = ceil(num_layers / cols)\n",
    "    \n",
    "    # Create a Plotly figure with subplots\n",
    "    fig = make_subplots(\n",
    "        rows=rows, cols=cols,x_title=f\"SAE features for TAG: {tag}\",\n",
    "        subplot_titles=list(layer_data.keys()),\n",
    "        horizontal_spacing=0.1, vertical_spacing=0.2\n",
    "    )\n",
    "    \n",
    "    # Add data to subplots\n",
    "    for i, (layer_name, features) in enumerate(layer_data.items()):\n",
    "        top_features = features[:top_n]\n",
    "        feature_labels, weights = zip(*top_features)\n",
    "        feature_labels = [str(label) for label in feature_labels]\n",
    "        \n",
    "        # Determine the row and column for the subplot\n",
    "        row = i // cols + 1\n",
    "        col = i % cols + 1\n",
    "        \n",
    "        # Add a bar chart for the layer\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=feature_labels, y=weights, name=layer_name),\n",
    "            row=row, col=col\n",
    "        )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=300 * rows,  # Adjust height based on rows\n",
    "        title_text=\"Top Features by Layer\",\n",
    "        title_x=0.5,\n",
    "        showlegend=False,\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Feature Number\", tickangle=90)\n",
    "    fig.update_yaxes(title_text=\"Weight\")\n",
    "\n",
    "    fig.write_image(\"SAE_top_features_for_tag.png\")\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "sorted_weights = get_sorted_weights_by_layer(tag)\n",
    "plot_layer_features(sorted_weights, top_n=20, tag=tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0884d023-8570-4299-b276-74dad62a2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_layer_features(sorted_weights, tag, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d160bc6f-4c99-4370-a5ca-228a038f8398",
   "metadata": {},
   "source": [
    "### Monitor reconstruction Errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f34e36-f869-47e4-90c5-c133ce4259d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_error_by_k_and_layer = sae_collector.get_avg_reconstruction_error_for_all_k_and_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c8c48-9e04-4696-923f-0a5184a2c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_error_by_k_and_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a1d6ef-3e6b-4da0-8386-7c9ba7064232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer_curves(layer_data, cols=2):\n",
    "    \"\"\"\n",
    "    Plot cumulative error against features included for each layer in a grid layout.\n",
    "\n",
    "    Parameters:\n",
    "    layer_data (dict): Dictionary mapping layer names to dictionaries of {features_included: cumulative_error}.\n",
    "                       Example:\n",
    "                       {\n",
    "                           \"Layer A\": {100: 0, 80: 0.1, 60: 0.3, 40: 0.6, 20: 0.8, 0: 1},\n",
    "                           \"Layer B\": {120: 0, 100: 0.05, 80: 0.15, 60: 0.4, 40: 0.65, 20: 0.85, 0: 1}\n",
    "                       }\n",
    "    cols (int): Number of columns in the grid layout. Default is 2.\n",
    "    \"\"\"\n",
    "    # Calculate number of layers and rows required\n",
    "    num_layers = len(layer_data)\n",
    "    rows = ceil(num_layers / cols)\n",
    "\n",
    "    # Create a subplot figure\n",
    "    fig = make_subplots(\n",
    "        rows=rows, cols=cols,\n",
    "        subplot_titles=list(layer_data.keys()),\n",
    "        horizontal_spacing=0.1, vertical_spacing=0.2\n",
    "    )\n",
    "\n",
    "    # Add traces for each layer\n",
    "    for i, (layer_name, data) in enumerate(layer_data.items()):\n",
    "        # Sort features to ensure the order is descending by keys (features included)\n",
    "        sorted_data = sorted(data.items(), key=lambda x: x[0], reverse=True)\n",
    "        features, errors = zip(*sorted_data)\n",
    "\n",
    "        # Determine the row and column for the subplot\n",
    "        row = i // cols + 1\n",
    "        col = i % cols + 1\n",
    "\n",
    "        # Add a line trace for the current layer\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=features, y=errors,\n",
    "                mode='lines+markers',\n",
    "                name=layer_name,\n",
    "                line=dict(width=2),\n",
    "                marker=dict(size=6)\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=300 * rows,  # Adjust height based on number of rows\n",
    "        width=800,  # Fixed width\n",
    "        title_text=\"Cumulative Error vs Features Included\",\n",
    "        title_font_size=24,\n",
    "        title_x=0.5,\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Features Included\")  # Reverse x-axis for descending features\n",
    "    fig.update_yaxes(title_text=\"Cumulative Error\")\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "    fig.write_image(\"reconstruction_loss_curves.png\")\n",
    "\n",
    "plot_layer_curves(reconstruction_error_by_k_and_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab33a6-d645-4d78-a04d-ca22bffd53f7",
   "metadata": {},
   "source": [
    "### Monitor Ablation Errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
