{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d6b3b0-a4c8-46ca-b785-bf521ce91b8d",
   "metadata": {},
   "source": [
    "### Load in the SAEs from Huggingface Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ead171-4c94-4fd6-8d84-90e1e47649a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import nnsight\n",
    "import sae\n",
    "import torch\n",
    "import torch.fx\n",
    "\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import snapshot_download\n",
    "from nnsight import NNsight, LanguageModel\n",
    "from sae import Sae\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from TinySQL import sql_interp_model_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9215a96-a9b6-42cd-86f5-5e663ae3cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"withmartian/sql_interp_saes\"\n",
    "\n",
    "# Change this to work with another model alias.\n",
    "model_alias = \"saes_bm1_cs1\"\n",
    "cache_dir = \"working_directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91567a0a-9f42-4597-ac28-6cbfa56ee7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelDatasetFullName:\n",
    "    model_id: str\n",
    "    dataset_id: str\n",
    "    full_dataset_name: str\n",
    "    full_model_name: str\n",
    "\n",
    "    def load_model(self):\n",
    "        model = AutoModelForCausalLM.from_pretrained(full_model_name)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3878fa9-d799-4503-b84f-2d03fc689567",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SaeOutput:\n",
    "    sae_name: str\n",
    "    text: str\n",
    "    tokens: list[str]\n",
    "    tags_by_index: list[str]\n",
    "    feature_acts_and_indices: list[list[(float, int)]]\n",
    "    features_indices: list[list[int]]\n",
    "\n",
    "\n",
    "@dataclass \n",
    "class GroupedSaeOutput:\n",
    "    sae_outputs_by_layer: dict[str, SaeOutput]\n",
    "    text: str\n",
    "    tokens: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5596f-ff6f-43fe-be3a-61f457715482",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = Path(\n",
    "    snapshot_download(repo_name, allow_patterns=f\"{model_alias}/*\", local_dir=cache_dir)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff27fe-0c74-46a2-acf2-d16a49e02794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(example):\n",
    "    alpaca_prompt = \"### Instruction: {} ### Context: {} ### Response: \"\n",
    "    example['prompt'] = alpaca_prompt.format(example['english_prompt'], example['create_statement'])\n",
    "    example['response'] = example['sql_statement']\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83cbdd3-5fee-459f-b5ab-e1ea381227aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadedSAES:\n",
    "    def __init__(self, dataset_name: str, full_model_name: str, model_alias: str,\n",
    "        tokenizer: AutoTokenizer, language_model: LanguageModel, layers: list[str],\n",
    "        layer_to_directory: dict, k: str, base_path: str, layer_to_saes: dict):\n",
    "\n",
    "        self.dataset_name = dataset_name\n",
    "        self.full_model_name = full_model_name\n",
    "        self.model_alias = model_alias\n",
    "        self.tokenizer = tokenizer\n",
    "        self.language_model = language_model\n",
    "        self.layers = layers\n",
    "        self.layer_to_directory = layer_to_directory\n",
    "        self.k = k\n",
    "        self.base_path = base_path\n",
    "        self.layer_to_saes = layer_to_saes\n",
    "\n",
    "        self.dataset = self.get_dataset()\n",
    "        self.mapped_dataset = self.dataset.map(format_example)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_all_subdirectories(path):\n",
    "        subdirectories = [\n",
    "            os.path.join(path, name) for name in os.listdir(path) \n",
    "            if os.path.isdir(os.path.join(path, name)) and not name.startswith(\".\")\n",
    "        ]\n",
    "        return subdirectories\n",
    "\n",
    "    def nnsight_eval_string_for_layer(self, layer: str):\n",
    "        \"\"\"\n",
    "        Converts transformer.h[0].mlp into self.language_model.transformer.h[0].mlp.output.save() for nnsight\n",
    "        \"\"\"\n",
    "        subbed_layer = re.sub(r'\\.([0-9]+)\\.', r'[\\1].', layer)\n",
    "        return f\"self.language_model.{subbed_layer}.output.save()\"\n",
    "\n",
    "    def encode_to_activations_for_layer(self, text: str, layer: str):\n",
    "        if \"bm1\" in self.full_model_name:\n",
    "            with self.language_model.trace() as tracer:\n",
    "                with tracer.invoke(text) as invoker:\n",
    "                    eval_string = self.nnsight_eval_string_for_layer(layer)\n",
    "                    my_output = eval(eval_string)\n",
    "        if len(my_output) > 1:\n",
    "            return my_output[0]\n",
    "        else:\n",
    "            return my_output\n",
    "\n",
    "    def encode_to_sae_for_layer(self, text: str, layer: str):\n",
    "        activations = self.encode_to_activations_for_layer(text, layer)\n",
    "        print(f'Activations are {activations.shape} at {layer}')\n",
    "\n",
    "        raw_acts = activations[0].detach().numpy().tolist()\n",
    "        \n",
    "        relevant_sae = self.layer_to_saes[layer]\n",
    "        sae_acts_and_features = relevant_sae.encode(activations)\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "\n",
    "        top_acts = sae_acts_and_features.top_acts[0].detach().numpy().tolist()\n",
    "        top_indices = sae_acts_and_features.top_indices[0].detach().numpy().tolist()\n",
    "\n",
    "        zipped_acts_and_indices = [[(f, i) for f, i in zip(float_sublist, int_sublist)]\n",
    "               for float_sublist, int_sublist in zip(top_acts, top_indices)]\n",
    "\n",
    "        sae_output = SaeOutput(\n",
    "            sae_name=layer, text=text, tokens=tokens, feature_acts_and_indices=zipped_acts_and_indices, \n",
    "            features_indices=top_indices\n",
    "        )\n",
    "        \n",
    "        return sae_output\n",
    "\n",
    "    def encode_to_all_saes(self, text: str):\n",
    "        sae_outputs_by_layer = {layer: self.encode_to_sae_for_layer(text=text, layer=layer) for layer in self.layers}\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "\n",
    "        return GroupedSaeOutput(sae_outputs_by_layer=sae_outputs_by_layer, text=text, tokens=tokens, tags=[])\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def load_from_path(model_alias: str, k: str):\n",
    "        k = str(k)\n",
    "        \n",
    "        base_path = f\"{cache_dir}/{model_alias}/k={k}\"\n",
    "        \n",
    "        print(f\"Loading from path {base_path}\")\n",
    "        subdirectories = LoadedSAES.get_all_subdirectories(base_path)\n",
    "        \n",
    "        layer_to_directory = {\n",
    "            directory.split(\"/\")[-1] : directory for directory in subdirectories\n",
    "        }\n",
    "        layers = sorted(list(layer_to_directory.keys()))\n",
    "\n",
    "        with open(f\"{base_path}/model_config.json\",  \"r\") as f_in:\n",
    "            model_config = json.load(f_in)\n",
    "\n",
    "            dataset_name = model_config[\"dataset_name\"]\n",
    "            full_model_name = model_config[\"model_name\"]\n",
    "            language_model = LanguageModel(full_model_name)\n",
    "            tokenizer = language_model.tokenizer\n",
    "\n",
    "        layer_to_saes = {layer: Sae.load_from_disk(directory) for layer, directory in layer_to_directory.items()}\n",
    "\n",
    "        return LoadedSAES(dataset_name=dataset_name, full_model_name=full_model_name,\n",
    "                          model_alias=model_alias, layers=layers, layer_to_directory=layer_to_directory,\n",
    "                          tokenizer=tokenizer, k=k, base_path=base_path,\n",
    "                          layer_to_saes=layer_to_saes, language_model=language_model)\n",
    "\n",
    "    def get_dataset(self):\n",
    "        return load_dataset(self.dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f0a3dd-0975-419f-8480-bd978044d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_saes = LoadedSAES.load_from_path(model_alias=model_alias, k=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b903ab-c4fe-40c4-82d5-3a0705845e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaeCollector:\n",
    "    \"\"\"\n",
    "    This class is responsible for collecting a large amount of text,\n",
    "    assigning tags to each token for a feature name, and also SAE outputs.\n",
    "    These can then be used for probes and feature analysis.\n",
    "    (Still to add: ablations.)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loaded_saes, restricted_tags=None):\n",
    "        self.loaded_saes = loaded_saes\n",
    "        self.restricted_tags = restricted_tags or []\n",
    "        self.mapped_dataset = loaded_saes.mapped_dataset\n",
    "        self.tokenizer = self.loaded_saes.tokenizer\n",
    "        self.supported_token_tags = {'last_token', 'eng_table_name', 'eng_field_name'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
