{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd16be97-a5ea-40dc-a18a-45aa312cd86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a8a5ce8-b91f-4bcb-9809-81c0bb70ace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1dfdb52afd47f8a061515da575ada2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/884 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eaffc0fef5c4921b0c8ba6e1467cf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/37.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e71e4642e0a4a3f80a20bcc02f7ce4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/6.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05867e53b4c9405d838ac5fdf5de839f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/4.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057e1a1488794368acb23de8c90cd16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/76500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40355c5291147a381077ca52c504710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45820f6c27c1464290d55f7adf770035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cs1 = load_dataset(\"withmartian/cs1_dataset\")\n",
    "cs2 = load_dataset(\"withmartian/cs2_dataset\")\n",
    "cs3 = load_dataset(\"withmartian/cs3_dataset\")\n",
    "cs4 = load_dataset(\"withmartian/cs5_dataset_synonyms\")\n",
    "cs5 = load_dataset(\"withmartian/cs5_dataset_synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "94b67859-58d4-410d-934f-1f7ab956c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = {\n",
    "    \"cs1\": cs1, \"cs2\": cs2, \"cs3\": cs3, \"cs4\": cs4, \"cs5\": cs5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "356bbf50-bbf5-4bb3-9541-fd8a861696aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fields_for_dataset(ds_name):\n",
    "    dataset = all_datasets[ds_name]\n",
    "    all_fields = dataset['table_fields']\n",
    "    all_names = set()\n",
    "\n",
    "    for item in all_fields:\n",
    "        all_x = json.loads(item)\n",
    "        for subitem in all_x:\n",
    "            all_names.add(subitem['name'])\n",
    "    all_field_names = set(all_names)\n",
    "\n",
    "    return len(all_field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4da9585c-9850-464d-a12b-34f6ff1c758a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_fields_for_dataset(\"cs5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6a59d74c-15fc-462b-a8a5-5525c4605e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nimport json\\nfield_counts = {}\\nfor name, ds in dataset_list.items():\\n    # Get the length of \\'table_fields\\' for each row\\n    for row in ds:\\n        fields = json.load(row[\\'table_fields\\'])\\n\\n        counts = [row[\\'table_fields\\'] for row in ds]\\n        field_counts[name] = counts\\n\\n# Plot the distributions\\nplt.figure(figsize=(10, 6))\\n\\nfor name, counts in field_counts.items():\\n    plt.hist(counts, bins=range(0, max(counts) + 2), alpha=0.6, label=name)\\n\\nplt.xlabel(\"Number of Table Fields\")\\nplt.ylabel(\"Frequency\")\\nplt.title(\"Distribution of Table Fields per Dataset\")\\nplt.legend()\\nplt.grid(True)\\nplt.tight_layout()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import json\n",
    "field_counts = {}\n",
    "for name, ds in dataset_list.items():\n",
    "    # Get the length of 'table_fields' for each row\n",
    "    for row in ds:\n",
    "        fields = json.load(row['table_fields'])\n",
    "\n",
    "        counts = [row['table_fields'] for row in ds]\n",
    "        field_counts[name] = counts\n",
    "\n",
    "# Plot the distributions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for name, counts in field_counts.items():\n",
    "    plt.hist(counts, bins=range(0, max(counts) + 2), alpha=0.6, label=name)\n",
    "\n",
    "plt.xlabel(\"Number of Table Fields\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Table Fields per Dataset\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c2bf4da8-8985-445f-8031-98b4af366efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_join = train.filter(lambda x: \"JOIN\" in x['sql_statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6029cf2f-d8ce-4a97-b16c-6dc1a6ee2ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7299869281045752"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(has_join) / len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f738da0d-a0c0-4dc6-98ef-7e412eeb697b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "790b145f-2c4a-4c43-91c3-0a83c8120188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 1: unexpected EOF while looking for matching `\"'\n",
      "/bin/bash: -c: line 2: syntax error: unexpected end of file\n",
      "fatal: destination path 'Experimental-Analysis-of-Text-to-SQL-Benchmarks' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! rm -rf \"Experimental-Analysis-Of-Text-to-SQL-Benchmarks\n",
    "! git clone https://github.com/athenarc/Experimental-Analysis-of-Text-to-SQL-Benchmarks.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "996d110e-b652-48fb-bdf3-e9993cbae0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DatasetAnalysisTools.QuestionInfo.question_info import QuestionInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "724f7e74-8a82-4761-a767-cda3e5153266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "all_questions = {\n",
    "    name: random.sample(dataset['english_prompt'], 100) for name, dataset in all_datasets.items()\n",
    "}\n",
    "# rarity , lexical_density, readability\n",
    "all_question_infos = {name: [] for name in all_questions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c7b4cf6f-8ba0-4b79-8ee4-28701c704115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 659481.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 966429.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 1008246.15it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 975419.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 1048576.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for name in all_questions:\n",
    "    prompt_list = all_questions[name]\n",
    "    for prompt in tqdm(prompt_list):\n",
    "        all_question_infos[name].append(QuestionInfo(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c6f50-1dfa-44ba-98e2-7f173893f278",
   "metadata": {},
   "source": [
    "try:\n",
    "    metrics_sum[\"avg_dependency_distance\"] += q.avg_dependency_distance()\n",
    "    metrics_count[\"avg_dependency_distance\"] += 1\n",
    "except Exception:\n",
    "    continue  # skip this entry for avg_dependency_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f78c4484-3280-47b5-878c-7b2e1873e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_metrics(all_question_infos):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for name, question_info_list in all_question_infos.items():\n",
    "        metrics_sum = defaultdict(float)\n",
    "        metrics_count = {\n",
    "            \"rarity\": len(question_info_list),\n",
    "            \"lexical_density\": len(question_info_list),\n",
    "            \"readability\": len(question_info_list),\n",
    "            #\"avg_dependency_distance\": 0  # we will count valid ones only\n",
    "        }\n",
    "\n",
    "        for q in tqdm(question_info_list):\n",
    "            metrics_sum[\"rarity\"] += q.rarity()\n",
    "            metrics_sum[\"lexical_density\"] += q.lexical_density()\n",
    "            metrics_sum[\"readability\"] += q.readability()\n",
    "\n",
    "        result[name] = {\n",
    "            metric: (metrics_sum[metric] / metrics_count[metric]) if metrics_count[metric] > 0 else None\n",
    "            for metric in metrics_sum\n",
    "        }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fcf2d052-b8db-4d7f-8ae3-7faed40c0459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:10<00:00,  4.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:11<00:00,  4.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████| 50/50 [00:17<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "average_metrics = compute_average_metrics(all_question_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e8075238-a63b-4e0a-8724-6f9cdde737ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cs1': {'rarity': 0.48664502164502177,\n",
       "  'lexical_density': 0.5667165344526701,\n",
       "  'readability': 43.357913486513496},\n",
       " 'cs2': {'rarity': 0.5201205213774873,\n",
       "  'lexical_density': 0.563464551365315,\n",
       "  'readability': 34.452503340493756},\n",
       " 'cs3': {'rarity': 0.4443002456306401,\n",
       "  'lexical_density': 0.6114780453597067,\n",
       "  'readability': 27.759909674365655},\n",
       " 'cs4': {'rarity': 0.4264464085474849,\n",
       "  'lexical_density': 0.5814865199898035,\n",
       "  'readability': 28.427202405748663},\n",
       " 'cs5': {'rarity': 0.4602144079689559,\n",
       "  'lexical_density': 0.5953473083834021,\n",
       "  'readability': 21.179168784371758}}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a1b11e1f-38d1-492b-94c4-56ed803ea429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rarity , lexical_density, readability, avg_dependency_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c051930f-a57d-48b4-b786-422071ec7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(input_string):\n",
    "    q_info = QuestionInfo(input_string)\n",
    "    return q_info\n",
    "\n",
    "q_info = get_metrics(\"What is the capital of California? Is it very far from texas and the capital of it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e0105ae-fba1-4aa8-bd6b-a589665c5ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexical density\n",
    "# readability\n",
    "# rarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fc966b85-ca53-41ca-9be4-8507920ef88f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No java install detected. Please install java to use language-tool-python.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[138]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mq_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrammar_errors_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/codes/TinySQL/notebooks/Experimental-Analysis-of-Text-to-SQL-Benchmarks/DatasetAnalysisTools/QuestionInfo/question_info.py:131\u001b[39m, in \u001b[36mQuestionInfo.grammar_errors_num\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgrammar_errors_num\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     tool = \u001b[43mlanguage_tool_python\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLanguageTool\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43men-US\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     matches = tool.check(\u001b[38;5;28mself\u001b[39m.question)\n\u001b[32m    135\u001b[39m     tool.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tiny/lib/python3.11/site-packages/language_tool_python/server.py:121\u001b[39m, in \u001b[36mLanguageTool.__init__\u001b[39m\u001b[34m(self, language, motherTongue, remote_server, newSpellings, new_spellings_persist, host, config, language_tool_download_version)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._server_is_alive():\n\u001b[32m    120\u001b[39m     \u001b[38;5;28mself\u001b[39m._stop_consume_event = threading.Event()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_start_server_on_free_port\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m language \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tiny/lib/python3.11/site-packages/language_tool_python/server.py:513\u001b[39m, in \u001b[36mLanguageTool._start_server_on_free_port\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28mself\u001b[39m._url = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttp://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._host\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._port\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/v2/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m513\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_start_local_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    514\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ServerError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tiny/lib/python3.11/site-packages/language_tool_python/server.py:539\u001b[39m, in \u001b[36mLanguageTool._start_local_server\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    522\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    523\u001b[39m \u001b[33;03mStart the local LanguageTool server.\u001b[39;00m\n\u001b[32m    524\u001b[39m \u001b[33;03mThis method starts a local instance of the LanguageTool server. If the \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    536\u001b[39m \u001b[33;03m:raises ServerError: If the server is already running or cannot be started.\u001b[39;00m\n\u001b[32m    537\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    538\u001b[39m \u001b[38;5;66;03m# Before starting local server, download language tool if needed.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[43mdownload_lt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlanguage_tool_download_version\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    540\u001b[39m err = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tiny/lib/python3.11/site-packages/language_tool_python/download_lt.py:211\u001b[39m, in \u001b[36mdownload_lt\u001b[39m\u001b[34m(language_tool_version)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_lt\u001b[39m(language_tool_version: Optional[\u001b[38;5;28mstr\u001b[39m] = LTP_DOWNLOAD_VERSION) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    197\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[33;03m    Downloads and extracts the specified version of LanguageTool.\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[33;03m    This function checks for Java compatibility, creates the necessary download\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    208\u001b[39m \u001b[33;03m    :raises ValueError: If the specified version format is invalid.\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[43mconfirm_java_compatibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage_tool_version\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m     download_folder = get_language_tool_download_path()\n\u001b[32m    215\u001b[39m     \u001b[38;5;66;03m# Use the env var to the jar directory if it is defined\u001b[39;00m\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# otherwise look in the download directory\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/tiny/lib/python3.11/site-packages/language_tool_python/download_lt.py:86\u001b[39m, in \u001b[36mconfirm_java_compatibility\u001b[39m\u001b[34m(language_tool_version)\u001b[39m\n\u001b[32m     84\u001b[39m java_path = which(\u001b[33m'\u001b[39m\u001b[33mjava\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m java_path:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[32m     87\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mNo java install detected. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     88\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mPlease install java to use language-tool-python.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     89\u001b[39m     )\n\u001b[32m     91\u001b[39m output = subprocess.check_output([java_path, \u001b[33m'\u001b[39m\u001b[33m-version\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     92\u001b[39m                                  stderr=subprocess.STDOUT,\n\u001b[32m     93\u001b[39m                                  universal_newlines=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     95\u001b[39m major_version, minor_version = parse_java_version(output)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No java install detected. Please install java to use language-tool-python."
     ]
    }
   ],
   "source": [
    "q_info.grammar_errors_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dafa4918-d1ea-4fc4-ae82-b1299c24d918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_get_nlp_question',\n",
       " '_get_schema_references',\n",
       " '_process_schema_elements',\n",
       " '_question_syntax_tree',\n",
       " 'avg_dependency_distance',\n",
       " 'dependencies_num',\n",
       " 'depth',\n",
       " 'grammar_errors_num',\n",
       " 'lexical_density',\n",
       " 'nlp_question',\n",
       " 'question',\n",
       " 'question_len',\n",
       " 'question_words_freqs',\n",
       " 'rarity',\n",
       " 'readability',\n",
       " 'referenced_schema_elements',\n",
       " 'referenced_schema_elements_percentage',\n",
       " 'schema_elements',\n",
       " 'schema_references',\n",
       " 'sql_query_schema_elements']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(q_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e4bacb-1e65-401e-bb56-af54602e4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install spacy textstat language_tool_python wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6575c-03c9-4148-8b4a-dbfdb3fce34b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
